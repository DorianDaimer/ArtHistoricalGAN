{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtHistoricalGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfh81lncG4MN",
        "colab_type": "text"
      },
      "source": [
        "# **Art historical GAN**<br>\n",
        "\n",
        "This notebook contains the code to implement and train the networks described in the thesis \"Latent Space Analysis in an Art Creating GAN\". <br>\n",
        "\n",
        "There is no setup required. Simply clone this repo to Google Drive and run this notebook with Google Colaboratory.<br> \n",
        "\n",
        "The 128x128 pixel data set can be downloaded from Drive as it is to large to be uploaded on Github. Alternatively the code can be run with the 64x64 pixel data set from the data folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3YbgV6_0y7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOnzkyRnIEgD",
        "colab_type": "text"
      },
      "source": [
        "Mount Drive and unzip the data archive on the virtual maschine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuCgq-5UIGAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFGw8k-pIQvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/ArtHistoricalGAN/data/64.zip' # adopt this path if using the 128x128 data set\n",
        "!cp {zip_path} .\n",
        "!unzip -q 64.zip -d Images\n",
        "!rm 64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNecGNL9Kw9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a path to save models and output images to\n",
        "RES_PATH = 'drive/My Drive/ArtHistoricalGAN/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZP1aVWCIH17",
        "colab_type": "text"
      },
      "source": [
        "Make the wikiart_genre file available in the Colab session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8ovov14JFjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ArtHistoricalGAN/utility')\n",
        "import wikiart_genre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5BySfDCKKzy",
        "colab_type": "text"
      },
      "source": [
        "Check if files were properly unzipped or just look through some images from the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nikC78rdKUvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "img_path = Path(\"Images/Expressionism/4.jpg\")\n",
        "image = Image.open(img_path).convert(mode=\"RGB\")\n",
        "image = np.asarray(image)\n",
        "plt.imshow(image);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsiR4zPnKnWY",
        "colab_type": "text"
      },
      "source": [
        "**Build the WGAN-GP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVwis9TdKm79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, LayerNormalization\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "\n",
        "# Define auxillary class for gradient penalty\n",
        "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
        "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
        "    def __init__(self, batch_size=BATCH_SIZE):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        alpha = tf.random.uniform(shape=(self.batch_size, 1, 1, 1), maxval=1)\n",
        "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
        " \n",
        "class WGAN_GP():\n",
        "    def __init__(self):\n",
        "        # Input shape\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        # critic iterations for each gen update\n",
        "        self.n_critic = 10\n",
        "        self.num_classes = 5\n",
        "        self.latent_dim = 128\n",
        "        # gradient penalty weight\n",
        "        self.LAMBDA = 10\n",
        "        self.losslog = []\n",
        "        self.batch_size=90\n",
        "\n",
        "        #optimizer = Adam(0.0001, beta_1=0.5, beta_2=0.9)\n",
        "        optimizer = RMSprop(0.00005)\n",
        "\n",
        "        # Build the generator and critic\n",
        "        self.generator = self.build_generator()\n",
        "        self.critic = self.build_critic()\n",
        "\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #       for the Critic\n",
        "        #-------------------------------\n",
        "\n",
        "        # Freeze generator's layers while training critic\n",
        "        self.generator.trainable = False\n",
        "\n",
        "        # Image input (real sample)\n",
        "        real_img = Input(shape=self.img_shape)\n",
        "\n",
        "        # Noise input\n",
        "        z_disc = Input(shape=(self.latent_dim,))\n",
        "        # Generate image based of noise (fake sample)\n",
        "        fake_img = self.generator(z_disc)\n",
        "\n",
        "        # Discriminator determines validity of the real and fake images\n",
        "        fake = self.critic(fake_img)\n",
        "        valid = self.critic(real_img)\n",
        "\n",
        "        # Construct weighted average between real and fake images\n",
        "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
        "        # Determine validity of weighted sample\n",
        "        validity_interpolated = self.critic(interpolated_img)\n",
        "\n",
        "        # Use Python partial to provide loss function with additional\n",
        "        # 'averaged_samples' argument\n",
        "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
        "                          averaged_samples=interpolated_img)\n",
        "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
        "\n",
        "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
        "                            outputs=[valid, fake, validity_interpolated])\n",
        "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
        "                                        self.wasserstein_loss,\n",
        "                                        partial_gp_loss], optimizer=optimizer,\n",
        "                                        loss_weights=[1, 1, self.LAMBDA])\n",
        "        #-------------------------------\n",
        "        # Construct Computational Graph\n",
        "        #         for Generator\n",
        "        #-------------------------------\n",
        "\n",
        "        # For the generator we freeze the critic's layers\n",
        "        self.critic.trainable = False\n",
        "        self.generator.trainable = True\n",
        "\n",
        "        # Noise input\n",
        "        z_gen = Input(shape=(self.latent_dim,))\n",
        "        # generate image\n",
        "        img = self.generator(z_gen)\n",
        "        # critic determines validity \n",
        "        valid = self.critic(img)\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z_gen, valid)\n",
        "        self.combined.compile(loss=self.wasserstein_loss, optimizer=optimizer) # loss weight to force different imgs for different labels?!\n",
        "        \n",
        "    def _compute_gradients(self, tensor, var_list):\n",
        "      grads = tf.gradients(tensor, var_list)\n",
        "      return [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(var_list, grads)]\n",
        "    \n",
        "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
        "        \"\"\"\n",
        "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
        "        \"\"\"\n",
        "        gradients = self._compute_gradients(y_pred, [averaged_samples])[0]\n",
        "        # compute the euclidean norm by squaring ...\n",
        "        gradients_sqr = tf.math.square(gradients)\n",
        "        #   ... summing over the rows ...\n",
        "        gradients_sqr_sum = tf.math.reduce_sum(gradients_sqr,\n",
        "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "        #   ... and sqrt\n",
        "        gradient_l2_norm = tf.math.sqrt(gradients_sqr_sum)\n",
        "        # compute lambda * (1 - ||grad||)^2 still for each single sample, lambda is in loss weight already?\n",
        "        gradient_penalty = tf.math.square(1 - gradient_l2_norm)\n",
        "        # return the mean as loss over all the batch samples\n",
        "        return tf.math.reduce_mean(gradient_penalty)\n",
        "\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return tf.math.reduce_mean(y_true * y_pred)\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * self.img_rows * 2, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((8, 8, 512)))\n",
        "        model.add(UpSampling2D())\n",
        "        #16X16\n",
        "        model.add(Conv2D(512, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        #32x32\n",
        "        model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        #64x64\n",
        "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        #128x128\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "\n",
        "    def build_critic(self):\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Conv2D(16, kernel_size=3, strides=2, padding=\"same\", input_shape=self.img_shape))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(LayerNormalization(epsilon=1e-5))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(LayerNormalization(epsilon=1e-5))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(LayerNormalization(epsilon=1e-5))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(LayerNormalization(epsilon=1e-5))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        img = Input(shape=self.img_shape)\n",
        "\n",
        "        # Determine validity of the image\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, sample_interval=100, start_epoch=0, preiterations=0, batch_size=self.batch_size):\n",
        "        if start_epoch > 0:\n",
        "          self.generator.load_weights(RES_PATH + \"saved_model/generator_weights.hdf5\")\n",
        "          self.critic.load_weights(RES_PATH + \"saved_model/discriminator_weights.hdf5\")\n",
        "        # Dataset iterator\n",
        "        train_gen, dev_gen = wikiart_genre.load(batch_size)\n",
        "        train_gen = train_gen()\n",
        "        test_gen = dev_gen()\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake = np.ones((batch_size, 1))\n",
        "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
        "\n",
        "        # pretrain the discriminator if desired\n",
        "        for iterp in range(preiterations):\n",
        "          # Get the next batch of images.\n",
        "          imgs, labels = next(train_gen)\n",
        "          # scale between -1 and 1 to match gen output\n",
        "          imgs = (imgs.astype(np.float32) - 127.5) / 127.5\n",
        "          # Sample noise as generator input\n",
        "          noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "          # Train the critic\n",
        "          d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
        "                                                    [valid, fake, dummy])\n",
        "          if (iterp+1) % 100 == 0: \n",
        "            print (\"%d [D loss: %f] [D loss label: %f]\" % (iterp, d_loss[0], d_loss[1]))\n",
        "\n",
        "        for epoch in range(start_epoch, epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                imgs, labels = next(train_gen)\n",
        "                # scale between -1 and 1 to match gen output\n",
        "                imgs = (imgs.astype(np.float32) - 127.5) / 127.5\n",
        "                # Sample noise as generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "                # Train the critic\n",
        "                d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
        "                                                                [valid, fake, dummy])\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
        "            self.losslog.append([d_loss, g_loss])\n",
        "\n",
        "            # If at save interval => save generated image samples and models\n",
        "            if (epoch+1) % sample_interval == 0:\n",
        "                # save model and images\n",
        "                self.save_model()\n",
        "                self.sample_images(epoch)\n",
        "                # evaluate on test set\n",
        "                imgs, labels = next(test_gen)\n",
        "                # scale between -1 and 1 to match gen output\n",
        "                imgs = (imgs.astype(np.float32) - 127.5) / 127.5\n",
        "                # Sample noise as generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "                # Test the critic\n",
        "                d_loss_test = self.critic_model.test_on_batch([imgs, noise],\n",
        "                                                        [valid, fake, dummy])\n",
        "                # Test the generator\n",
        "                g_loss_test = self.combined.test_on_batch(noise, valid)\n",
        "\n",
        "                # Plot the progress\n",
        "                print (\"%d [D loss test: %f] [G loss test: %f]\" % (epoch, d_loss_test[0], g_loss_test))\n",
        "                with open(RES_PATH + 'loss.log', 'a') as f:\n",
        "                    for each in self.losslog:\n",
        "                        f.writelines('%s, %s\\n'%(each[0], each[1]))\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 10, 10\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        #sampled_labels = np.array([num for _ in range(20) for num in range(5)])\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(RES_PATH + \"images_%d.jpg\" % epoch)\n",
        "        plt.close()\n",
        "        \n",
        "    def generate_image(self):\n",
        "        self.generator.load_weights(RES_PATH + \"saved_model/generator_weights.hdf5\")\n",
        "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
        "        gen_img = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_img = 0.5 * gen_img + 0.5\n",
        "        plt.imshow(gen_img[0,:,:,:])\n",
        "        plt.axis('off')\n",
        "\n",
        "    def plot_images(self):\n",
        "        r, c = 5, 5\n",
        "        self.generator.load_weights(RES_PATH + \"saved_model/generator_weights.hdf5\")\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        #sampled_labels = np.array([num for _ in range(20) for num in range(5)])\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "        fig, axs = plt.subplots(r, c, figsize=(6,6))\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(RES_PATH + \"generated_images.jpg\")\n",
        "\n",
        "    def save_model(self):\n",
        "\n",
        "        def save(model, model_name):\n",
        "            model_path =  RES_PATH + \"saved_model/%s.json\" % model_name\n",
        "            weights_path = RES_PATH + \"saved_model/%s_weights.hdf5\" % model_name\n",
        "            options = {\"file_arch\": model_path,\n",
        "                        \"file_weight\": weights_path}\n",
        "            json_string = model.to_json()\n",
        "            open(options['file_arch'], 'w').write(json_string)\n",
        "            model.save_weights(options['file_weight'], overwrite=True)\n",
        "\n",
        "        save(self.generator, \"generator\")\n",
        "        save(self.critic, \"discriminator\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOUJGAnzNQ6k",
        "colab_type": "text"
      },
      "source": [
        "Initialize and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWjAJNoWNMku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wgan = WGAN_GP()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0zcHoeeNTwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wgan.train(epochs=10000, sample_interval=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlq6xQTDNdPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot and save 25 sample generated images\n",
        "wgan.plot_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si9YPDpcNiVF",
        "colab_type": "text"
      },
      "source": [
        "**Build and train the Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3cRPkR-NmqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYvfWJKiOTmI",
        "colab_type": "text"
      },
      "source": [
        "Construct and balance the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNO8tfKrOXyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = Path(\"Images/\")\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "BATCHSIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcWJB-f1OaQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  label_mode='categorical',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(DIM, DIM),\n",
        "  batch_size=BATCHSIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abnr1LGEOeim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  label_mode='categorical',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(DIM, DIM),\n",
        "  batch_size=BATCHSIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wb-7AGCOlog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_train_ds = (\n",
        "  train_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[0] == 1)\n",
        "    .repeat())\n",
        "exp_train_ds = (\n",
        "  train_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[1] == 1)\n",
        "    .repeat())\n",
        "gogh_train_ds = (\n",
        "  train_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[2] == 1)\n",
        "    .repeat())\n",
        "cez_train_ds = (\n",
        "  train_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[3] == 1)\n",
        "    .repeat())\n",
        "gaug_train_ds = (\n",
        "  train_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[4] == 1)\n",
        "    .repeat())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh7hsjb4OmpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_val_ds = (\n",
        "  val_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[0] == 1)\n",
        "    .repeat())\n",
        "exp_val_ds = (\n",
        "  val_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[1] == 1)\n",
        "    .repeat())\n",
        "gogh_val_ds = (\n",
        "  val_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[2] == 1)\n",
        "    .repeat())\n",
        "cez_val_ds = (\n",
        "  val_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[3] == 1)\n",
        "    .repeat())\n",
        "gaug_val_ds = (\n",
        "  val_ds\n",
        "    .unbatch()\n",
        "    .filter(lambda images, label: label[4] == 1)\n",
        "    .repeat())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWP9E4G0Ozn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resampled_train_ds = tf.data.experimental.sample_from_datasets([imp_train_ds, exp_train_ds, gogh_train_ds, cez_train_ds, gaug_train_ds], weights=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
        "resampled_train_ds = resampled_train_ds.batch(BATCHSIZE)\n",
        "\n",
        "resampled_val_ds = tf.data.experimental.sample_from_datasets([imp_val_ds, exp_val_ds, gogh_val_ds, cez_val_ds, gaug_val_ds], weights=[0.2, 0.2, 0.2, 0.2, 0.2])\n",
        "resampled_val_ds = resampled_val_ds.batch(BATCHSIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkQYgyGwO83o",
        "colab_type": "text"
      },
      "source": [
        "Print samples images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byzbUK2eO2ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in resampled_train_ds.take(1):\n",
        "  for i in range(25):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[np.where(labels[i] == 1)[0][0]])\n",
        "    plt.axis(\"off\")\n",
        "plt.savefig(RES_PATH + 'example_images.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeyxFhdFPM8U",
        "colab_type": "text"
      },
      "source": [
        "Prepare for training - this uses the unbalanced data set for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnxIk8C1PAEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(10000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6HgFXILPR8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(DIM, DIM,3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKnSL0Q5PSx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 5\n",
        "\n",
        "cls = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgqigSnJPXVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cls.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqBeD4D7PYAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "history = cls.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8NazTNfPr3Y",
        "colab_type": "text"
      },
      "source": [
        "Plot training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzAdOFmqPh9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "#plt.legend(loc='lower right')\n",
        "plt.ylabel('accuracy [%]')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training')\n",
        "plt.plot(epochs_range, val_loss, label='Validation')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.savefig(RES_PATH + 'training_cls.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy78fTnKPz8U",
        "colab_type": "text"
      },
      "source": [
        "**Latent Space Experiments** <br>\n",
        "\n",
        "Work in progess"
      ]
    }
  ]
}